---
title: "dynamite"
link-citations: true
output: html_document
bibliography: dynamite.bib
vignette: >
  %\VignetteIndexEntry{dynamite}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
```{r srr, eval = FALSE, echo = FALSE}
#' @srrstats {BS1.2b} *At least one package vignette, both as general and applied textual descriptions, and example code*
```

```{r setup}
library(dynamite)
```

# Introduction

The `dynamite` package provides easy-to-use interface for Bayesian inference of complex panel data. The main features distinguishing the package and the underlying methodology from many other approaches are 

* Support for both time-varying and time-invariant effects 
* Joint modelling of multiple measurements per individual (multiple channels)
* Support for non-gaussian observations
* Realistic counterfactual predictions which take account the dynamic structure of the model
* Clear quantification of parameter and predictive uncertainty due to Bayesian approach
* User-friendly and efficient R interface with state-of-the-art estimation via [@rstan] 

# Model

Consider an individual $i$ with observations $y_{i,t} = (y^1_{i,t}, \ldots, y^c_{i,t},\ldots, y^C_{i,t})$, $t=1,\ldots,T$, $i = 1,\ldots,N$ i.e. at each time point $t$ we have $C$ observations from $N$ individuals. Assume that each element of $y_{i,t}$ can depend on the past values $y_{i,t-1}$, as well as additional exogenous covariates $x_{i,t}$. Then, assuming that the elements of $y_{i,t}$ are independent given $y_{i, t-1}$ and $x_{i,t}$, we have
\[
\begin{aligned}
y_{i,t} &\sim p_t(y_{i,t} | y_{i,t-1},  x_{i,t}) = \prod_{c=1}^C p^c_t(y^c_{i,t} | y^1_{i,t-1}, \ldots, y^C_{i,t-1}, x_{i,t}).
\end{aligned}
\]
Here the parameters of the conditional distributions $p^c$ depend on time, which allows us to take into account the fact that the dynamics of our system can evolve over time. 

For $p^c_t$, given a suitable link function depending on our distributional assumptions, we define a linear predictor $\eta^c_{t}$ for the channel $c$ with a following general form:
\[
\begin{aligned}
\eta^c_{t} &= \alpha^c_{t} + Z^c_{t} \beta^c + X^c_{t} \delta^c_{t}
\end{aligned}
\]
where $\alpha_t$ (possibly time-varying) is the intercept term, $Z^c_t$ defines the predictors corresponding to the vector of time-invariant coefficients  $\beta^c$, and similarly for the time-varying part $X^c_{t} \delta^c_{t}$. For time-varying coefficients $\delta$ (and similarly for $\alpha$), we use Bayesian P-splines (penalized B-splines) [@lang2004] where
\[
\delta^c_{k,t} = B_t \omega_k^c, \quad k=1,\ldots,K,
\]
where $K$ is the number of covariates, $B_t$ is a vector of B-spline values at time $t$ and $\omega_k^c$ is vector of corresponding spline coefficients. In general the number of B-splines $D$ used for constructing the splines for the study period $1,\ldots,T$ can be chosen freely, bit too large $D$ can result in overfitting. To mitigate this, we define a random walk prior for $\omega^c_k$ as
\[
\begin{aligned}
\omega^c_{k,1} &\sim p(\omega^c_{k,1}),\
\omega^c_{k,d} &\sim N(\omega^c_{k,d-1}, (\tau^c_k)^2), \quad d=2,\ldots, D.\
\end{aligned}
\]
with user defined prior $p(\omega^c_{k,1})$ on the first coefficient, which due to the structure of $B_1$ corresponds to the prior on the $\delta^c_{k,1}$. Here, the parameter $\tau^c_k$ controls the smoothness of the spline curves.

# Defining the model

Currently the `dynamite` package supports the following distributions for the observations:

* Categorical: `categorical` (with a softmax link using the first category as reference). See the documentation of the `categorical_logit_glm` in the Stan function reference manual (https://mc-stan.org/users/documentation/).
* Gaussian: `gaussian` (identity link, parameterized using mean and standard deviation).
* Poisson: `poisson` (log-link, with an optional known offset variable).
* Negative-binomial: `negbin` (log-link, using mean and dispersion parameterization, with an optional known offset variable). See the documentation on `NegBinomial2` in the Stan function reference manual.
* Bernoulli: `bernoulli` (logit-link).
* Binomial: `binomial` (logit-link).
* Exponential: `exponential` (log-link).
* Gamma: `gamma` (log-link, using mean and shape parameterization).

The models in the `dynamite` package are defined by combining the channel-specific formulas defined via the R's formula syntax. Each channel is defined within a special `obs` function, and these are combined with `+`. For example a formula `obs(y ~ lag(x), family = "gaussian") + obs(x ~ z, family = "poisson")` defines a model with two channels; first we declare that `y` is a gaussian variable depending on a previous value of `x` (`lag(x)`), and then we add a second channel declaring `x` as Poisson distributed depending on some exogenous variable `z` (for which we do not define any distribution). 

The `dynamite` models do not support contemporaneous dependencies in order to avoid complex cyclic dependencies which would make handling missing data, subsequent predictions, and causal inference challenging or impossible. This is why we used `lag(x)` in the previous example, a shorthand for `lag(x, k = 1)`, which defines a one-step lag of the variable `x`. Longer lags can also be defined by adjusting the argument `k`. A special model component `lags` can also be used to quickly add lagged responses as predictors. This component adds a lagged value of each response in the model as a predictor to every channel. For example, calling `obs(y ~ z, family = "gaussian") + obs(x ~ z, family = "poisson") + lags(k = 1)` would add `lag(y, k = 1)` as a predictor of `x` and conversely, `lag(x, k = 1)` as a predictor of `y`. Just as with the function `lag()`, the argument `k` in `lags` can be adjusted to add longer lags of each response to each channel.
The inclusion of lagged response variables in the model implies that some time points have to be considered fixed in the estimation. The number of fixed time points in the model is equal to the largest shift value of any observed response variable in the model (defined either via `lag` or the global `lags`).

In addition to declaring response variables via `obs`, we can also use function `aux` to define auxiliary channels which are deterministic functions of other variables. Defining these auxiliary variables explicitly instead of defining them directly on the right-hand side of the formulas (i.e., by using the "as is" function `I()`) makes the subsequent prediction steps more clear and allows easier checks on the model validity. The values of auxiliary variables are computed dynamically during prediction, making the use of lagged values and other transformations possible. An example of a formula using an auxiliary channel could be `obs(y ~ lag(log1x), family = "gaussian") + obs(x ~ z, family = "poisson") + aux(log1x ~ log(1 + x))`. Note that the auxiliary channel can also depend on other variables without lags. The function `aux` also does not use the `family` argument, which is automatically set to `deterministic` and is a special channel type of `obs`. Note that lagged values of deterministic `aux` channels do not imply fixed time points. Instead they must be given starting values using a special function `past()`, which defines the starting values of the channel and its lags.

The formula within `obs` can also contain an additional special function `varying`, which defines the time-varying part of the model equation, in which case we could write for example `obs(x ~ z + varying(~ -1 + w), family = "poisson")`, which defines a model equation with a constant intercept and time-invariant effect of `z`, and a time-varying effect of `w`. We also remove the duplicate intercept with `-1` in order to avoid identifiability issues in the model estimation (we could also define a time varying intercept, in which case we would write `obs(x ~ -1 + z + varying(~ w), family = "poisson)`). The part of the formula not wrapped with `varying` is assumed to correspond to the fixed part of the model, so `obs(x ~ z + varying(~ -1 + w), family = "poisson")` is actually identical to `obs(x ~ -1 + fixed(~ z) + varying(~ -1 + w), family = "poisson")` and `obs(x ~ fixed(~ z) + varying(~ -1 + w), family = "poisson")`.

When defining varying effects, we also need to define how the these time-varying regression coefficient behave. For this, a `splines` component should be added to the model, e.g. `obs(x ~ varying(~ -1 + w), family = "poisson) + splines(df = 10)` defines a cubic B-spline with 10 degrees of freedom for the time-varying coefficient corresponding to the `w`. If the model contains multiple time-varying coefficients, same spline basis is used for all coefficients, with unique spline coefficients and their standard deviation, as defined in the previous Section.

It is also possible to define a random intercept term for each group by using `random_intercept = TRUE` inside the `obs` function. This leads to a model where the in addition to the common intercept each individual/group has their own intercept with zero-mean normal prior and unknown standard deviation, analogously with the typical mixed models. 

Finally, the declared model is supplied to `dynamite`, for which we also supply the data, optional user-defined priors for the model parameters, and additional arguments to the `rstan::sampling` which handles the model estimation. For example, `dynamite(obs(x ~ varying(~ -1 + w), family = "poisson) + splines(df = 10), data = d, time = "year", group = "id", chains = 2, cores = 2)` estimates the model using the data in the data frame `d`, which contains variables `year` and `id` (defining the time-index and group-index variables of the data). Arguments `chains` and `cores` are passed to `rstan::sampling`
which then uses to parallel Markov chains in the the Markov chain Monte Carlo (MCMC) sampling of the model parameters.

# Example

As an example, consider a following simulated multichannel data:

```{r}
library(dynamite)
head(multichannel_example)
```

<<<<<<< HEAD
The data is in a long format (as required by the `dynamite`), containing the 
firm id (`firm`, 10 firms), the `year` (20 years), value of the firm (`value`) , the firmsâ€™ gross investment (`invest`) and stock of plant and equipment (`capital`). 
=======
The data is in a long format (as required by the `dynamite`), containing the variables
`id` (50 unique firms), the `time` (20 time points), a continuous variable `g`, a varible with non-negative integer values `p`, and a binary varible `b`. We define a following model (which actually matches the data generating process used in simulating the data):

```{r}
set.seed(1)
f <- obs(g ~ lag(g) + lag(logp), family = "gaussian") +
  obs(p ~ lag(g) + lag(logp) + lag(b), family = "poisson") +
  obs(b ~ lag(b) * lag(logp) + lag(b) * lag(g), family = "bernoulli") +
  aux(numeric(logp) ~ log(p + 1))
```
>>>>>>> 12368358ddadd7f7e4c3974baa37ab642ae13127

We can the fit the model using the `dynamite` function (note the small number of iterations and additional thinning in order to satisfy the CRAN requirements):
```{r, eval = FALSE}
multichannel_example_fit <- dynamite(
  f, multichannel_example, "id", "time",
  chains = 1, cores = 1, iter = 2000, warmup = 1000, init = 0, refresh = 0,
  thin = 5, save_warmup = FALSE)
```








# References
